#--------------------------------------------------------------------
# Step1: IMPORT NECESSARY LIBRARIES
#--------------------------------------------------------------------

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from scipy.stats import zscore
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

#--------------------------------------------------------------------
# Step2: IMPORT DATA
#--------------------------------------------------------------------
file_path = ('/Users/darienprall/Documents/GitHub/va_utilization/va_utilization_data.csv')
data = pd.read_csv(file_path)

#--------------------------------------------------------------------
# Step3: DEFINE & CLEAN DATA
# - 3.1: DEFINITIONS
# VETERANS WHO USED MULTIPLE PROGRAMS ARE COUNTED IN EACH PROGRAM BUT ONLY ONCE IN THE TOTAL
# THE SUM OF USERS IN EACH PROGRAM DOES NOT EQUAL TOTAL USERS
#
# State                                     The state of the feature data
# Total Veteran Population                  The total count of veterans in the given state
# Total VA Users: Veterans only             The total count of veterans utilizing the Veterans Affairs (does not include, active duty)
# VA Health Care                            The total count of veterans enrolled into the Veterans Affairs Health Care
# Disability Compensation OR Pension        The total count of veterans enrolled in disability compensation or pension
# VA Home Loan Guaranty                     The total count of veterans who utilized the Veterans Affairs Home Loan Guaranty
# VA Life Insurance                         The total count of veterans enrolled in the Veterans Affairs Life Insurance
# Education Benefits                        The total count of veterans utilizing educational benefits
# Memorial Benefits                         The total count of veterans utilizing memorial benefits
# Vocational Rehabilitation & Employment    The total count of veterans utilizing vocational rehabilitation & employment benefits
#
#--------------------------------------------------------------------

# - 3.2: CLEANING DATA
# - 3.2.1: Place all numerical categories in an array to loop through and convert
numerical_features = [
    'Total Veteran Population',
    'Total VA Users: Veterans only',
    'VA Health Care',
    'Disability Compensation OR Pension',
    'VA Home Loan Guaranty',
    'VA Life Insurance',
    'Education Benefits',
    'Memorial Benefits',
    'Vocational Rehabilitation & Employment'
]

# 3.2.2: Loop through numerical_features to remove commas, whitespace, tabs and convert to_numeric
for column in numerical_features:
    # Remove trailing and leading whitespace
    data[column] = data[column].str.strip()

    # Remove tabs and commas
    data[column] = data[column].replace({r'\t': '', r',': ''}, regex = True)

    # Convert to_numeric
    data[column] = pd.to_numeric(data[column], errors = 'coerce')

#print(data.head())

#--------------------------------------------------------------------
# Step4: SEARCH ALGORITHM DEMO (ANOMALY DETECTION)
# - In this example, I want to determine the top 5 states in which veterans are not using the VA
# - Here are my steps in solving this
# - 4.1: Calculate the utilization rate for each state (Utilization Rate = Total VA Users: Veterans only / Total Veteran Population)
# - 4.2: Apply a Z-score threshold of 2 or -2 to simplify the detection of anomalies 
# - 4.3: Sort the data by lowest utilization rate to determine the top 5 states
# - 4.4: Output the results
#--------------------------------------------------------------------

# - 4.1: Calculate Utilization Rate
data['Utilization Rate'] = data['Total VA Users: Veterans only'] / data['Total Veteran Population']
#print(data.head())

# - 4.2: Z-Scores with a threshold of 2
threshold = 2
data['Z-Score'] = zscore(data['Utilization Rate'])

# - 4.2.1: Anomaly Detection (any states > or < 2)
anomalies = data[data['Z-Score'].abs() > 2 ]
#print(anomalies)

# - 4.2.2: Filtering out anomalies
data_wo_anomalies = data[(data['Z-Score'] < threshold) & (data['Z-Score'] > -threshold)]
#print(data_wo_anomalies)


# - 4.3: Sorting the data
data_wo_anomalies_sorted = data_wo_anomalies.sort_values(by='Utilization Rate', ascending = True)
#print(data_wo_anomalies_sorted) 

# - 4.3.1: Determining Top 5 Lowest Utilization Rates
top_5_lowest_utilization_rates = data_wo_anomalies_sorted[['State', 'Utilization Rate']].head(5)

# - 4.4: Output
print("The top 5 states with the lowest utilization rates are as follows: ")
print("STATE\t\tUTILIZATION RATE")
for index, row in top_5_lowest_utilization_rates.iterrows():
    print(f"{row['State']}\t| {row['Utilization Rate']:.2f}")